---
title: "1079251"
format: html
editor: visual
---

## ![](images/ef31201f380cae10cb4cfffd860b5a0.png)

# Reading data

```{r}
#houskeeping
#Clear objects already in the environment – start with a clean slate
rm(list=ls())

#loading libraries
library(tidyverse)
library(svyVGAM)
library(sjlabelled)
library(desctable)
library(summarytools)
library(naniar)
library(Hmisc)
library(marginaleffects)
library(haven)
library(catregs)
library(margins)
library(modelsummary)
library(zoo)
library(stargazer)
library(texreg)
library(VIM)
library(lattice)
library(ggplot2)
library(plyr)
library(dplyr)
library(khb)
library(reshape2)
library(kableExtra)
library(lmtest)
library(rowr)
library(broom)
library(broom.mixed)
library(lme4)
library(lmerTest)
library(sjPlot)
library(plm)
library(estimatr)
library(rdrobust)
library(rddensity)
```

```{r}
#read all data
inpath<-"D:/r git projects/ox-R/AQM/"
climatesurvey <- read.csv(file=paste0(inpath, "climatesurvey.csv")) 
schoolsdata <- read.csv(file=paste0(inpath, "schoolsdata.csv")) 
nlsy18<-read.csv(file=paste0(inpath, "nlsy18plus_selection.csv"))
intern<-read.csv(file=paste0(inpath, "intern_data.csv"))
load("D:\\r git projects\\ox-R\\AQM\\gss_jazz.RData")
```

# Section A – OLS and logistic regression

## SECTION A1

For this question, you need to load the dataframe in gss_jazz.RData. These data come from the 1993round of the US General Social Survey (gss website). For more information, you can consult the1972-2022 cumulative codebook (3800 pages!) and data documentation on the website, but theyare not necessary for the completion of this question.Imagine you are a sociologist interested in cultural consumption and taste differences, who wants toknow if **there is an age difference in liking or not liking jazz**. You are asked to evaluate the **hypothesis that the association between age and liking jazz is different for men and women**.

1.Test the hypothesis with a logistic regression model and present the results in three ways: **logit coefficients**, **odds ratios**, and **predicted probabilities**. Explain how you test the hypothesis. Discuss and explain the results

To better test the interaction effects in the logistic regression, we will use the Mize's (2019) method of marginal effects and test of second differences because it answers what the effect of age on average for males or females on liking jazz and inform us where across the age range there are significant gender differences in age effects.

```{r}
#look at the distribution of the variables
summary(gss_jazz)
table(is.na(gss_jazz))

#build a model to estimate the gender differences in the effect of age on the probability of liking jazz
m1<-glm(jazz_n~ageq+sex+ageq*sex,data=gss_jazz,family = binomial(link="logit"))
```

```{r}
#using the catreg package, create an object design to compute the predicted probabilities
design<-margins.des(m1,ivs=expand.grid(sex=c("Male","Female"),ageq=c("Age 18-32","Age 32-44","Age 44-60","Age 60+")))
design

#plug in the model m1 and the design matrix into margins to check gender-related interaction effects
p1<-margins(m1,design)

#plot the probabilities of loving jazz by sex and age
figure1<-ggplot(data=p1,
       aes(x=ageq,y=fitted,
           group=sex,color=sex,
           ymin=fitted-se.fitted,ymax=fitted+se.fitted))+
        geom_line()+
        geom_ribbon(alpha=.1,colour="azure2")
figure1
#it looks like males are more likely to be jazz lovers if they are younger compared with their female peers, but for the older cohorts, this trend by gender reverses
```

The regression results of the m1 and figure1 show that only for the most senior age cohort (age 60+), there is an significant interaction effect of gender and age on liking jazz, with women age 60+ have the age effect of liking jazz of -1.08+0.64=-0.44 compared with men (-1.08).

```{r}
#1st way of checking the interactions: using the first and second differences to compare and calculate the standard error to derive the significance of the differences between men and women in each age cohort

#To deal with no numeric alike variable error when applying the first.diff.fitted, we assigned new values to each age cohort and transferred the sex cohort to numeric

jazz<-gss_jazz%>%select(jazz_n,ageq,sex)
jazz$ageq_new<-c(0)
jazz$ageq_new[jazz$ageq=="Age 18-32"]<-18
jazz$ageq_new[jazz$ageq=="Age 32-44"]<-32
jazz$ageq_new[jazz$ageq=="Age 44-60"]<-44
jazz$ageq_new[jazz$ageq=="Age 60+"]<-60

jazz$sex<-ifelse(jazz$sex=="Male",0,1) #female==1

#create a new design object and model
m1_new<-glm(jazz_n~ageq_new+sex+ageq_new*sex,data=jazz,family = binomial(link="logit"))
design_new<-margins.des(m1_new,ivs=expand.grid(sex=c(0,1),ageq_new=c(18,32,44,60)))


#show the gender comparison of predicted probabilities liking jazz in each age cohort
#age 18-32
f1<-data.frame(first.diff.fitted(m1_new,design_new,compare=c(1,2)))
#age 32-44
f2<-data.frame(first.diff.fitted(m1_new,design_new,compare=c(3,4)))
#age 44-60
f3<-data.frame(first.diff.fitted(m1_new,design_new,compare=c(5,6)))
#age 60+
f4<-data.frame(first.diff.fitted(m1_new,design_new,compare=c(7,8)))

dat1<-rbind(f1,f2,f3,f4)
rownames(dat1)<-c("Age 18-32","Age 32-44","Age 44-60","Age 60+")
dat1<-dat1%>%select(first.diff,std.error,p.value)
colnames(dat1)[1]<-"First/Second Difference"
```

It seems that for the youngest age cohort (age 18-32), there are some significant gender differences in liking jazz (corresponding to Figure 1), with men having a higher probability of liking jazz than women (0.088\*). However, for any other older age cohorts, these differences in predicted probabilities by gender vanish.

```{r}
#Now we use the second difference to examine whether the age effect on the probability of liking jazz is significantly different for men and women using the original model m1 with age cohort as a factorial variable

#age 18-32 & age 32-44
d1<-data.frame(second.diff.fitted(m1,design,compare=c(1,2,3,4)))
#age 18-32 & age 44-60
d2<-data.frame(second.diff.fitted(m1,design,compare=c(1,2,5,6)))
#age 18-32 & age 60+
d3<-data.frame(second.diff.fitted(m1,design,compare=c(1,2,7,8)))


#age 32-44 & age 44-60
d4<-data.frame(second.diff.fitted(m1,design,compare=c(3,4,5,6)))
#age 32-44 & age 60+
d5<-data.frame(second.diff.fitted(m1,design,compare=c(3,4,7,8)))

#age 44-60 & age 60+
d6<-data.frame(second.diff.fitted(m1,design,compare=c(5,6,7,8)))



#make a table for presenting the second difference test
dat2<-rbind(d1,d2,d3,d4,d5,d6)
rownames(dat2)<-c("Age 18-32 & Age 32-44","Age 18-32 & Age 44-60","Age 18-32 & Age 60+","Age 32-44 & Age 44-60","Age 32-44 & Age 60+","Age 44-60 & Age 60+")

dat2<-dat2%>%select(-term)
dat2<-dat2%>%select(est,std.error,p.value)
colnames(dat2)[1]<-"First/Second Difference"

dat3<-rbind(dat1,dat2)

table2<-kbl(dat3,caption = "First and second difference test for the interaction effects")%>%
kable_classic(full_width = F, html_font = "Cambria")%>%
pack_rows("First Difference",1,4)%>%
pack_rows("Second Difference",5,10)
```

It seems that only when comparing males and females in the youngest (18-32) and oldest (60+) cohorts, the interaction effect of age and gender is significant (0.155\*). That is, in comparing the youngest (18-32) and oldest (60+) cohorts, the age effect that make older adults less likely to have preference for jazz, is stronger for males than for females.

```{r}
#2nd way of checking the interactions: compare the average marginal effect of age on liking jazz by gender
cames<-summary(marginaleffects(m1,variables="ageq",by="sex"))
compare.margins(margins=cames$estimate,margins.ses = cames$std.error)

```

The p-value is 0.091 (larger than 0.05), and according to this analysis, there are no significant differences in the average marginal effects of age in liking jazz for men and women, at least not for only comparing the youngest (18-32) and oldest (60+) age cohorts.

```{r}
#present the results in three ways: logit coefficients, odds ratios, and predicted probabilities.

m2<-lm(jazz_n~ageq+sex+ageq*sex,data=gss_jazz)
#table summarizing model1 by logit coefficients+linear probability model
convertModel <- function(model) {
  tr <- createTexreg(
    coef.names = names(model$coef), 
    coef = as.numeric(summary(model)$coefficients[,1]), 
    se = as.numeric(summary(model)$coefficients[,2]), 
    pvalues = as.numeric(summary(model)$coefficients[,4]),
    gof.names = c("N","AIC"), 
    gof = c(nobs(model),AIC(model)), 
    gof.decimal = c(F,F)

  )
}
table1<-htmlreg(lapply(list(m1,m2), convertModel),file="logitp_compare.html",custom.model.names = c("Model 1 presented in logit coefficients","Model 2"),caption="Comparison of the logistic and linear probability model", 
        caption.above = TRUE)



#table summarizing model1 by odds ratios
table3<-modelsummary(list("Model 1"=m1),fmt=2,statistic = "conf.int",conf_level = 0.95,exponentiate = T,stars = T,title="Model 1 presented in odds ratios")
table3|>
    kable_classic(full_width = F, html_font = "Cambria")


#plot of predicted probabilities by age and sex
figure1


```

2.Test the hypothesis with a linear probability model. Explain the model and the results. Discuss how this compares to the logistic model and its results.

```{r}
#OLS on a binary variable
m2<-lm(jazz_n~ageq+sex+ageq*sex,data=gss_jazz)
summary(m2)
```

The linear probability model (m2) fits the ordinary least squared regression on a binary dependent variable and yields analogous results, similar to the logistic model (m1). The interaction effect of age and sex is only significant when comparing the youngest and oldest cohorts (0.15\*), which shows that compared with men in the youngest cohort and those in their sixties or older, there is a significant decrease in the likelihood of liking jazz (-0.26), whilst the age effect for women is more nuanced (-0.26+0.15=-0.11).

The linear probability model yields results that are easier to interpret than the logistic regression model; for example, m2 gives us a coefficient of -0.1 for sex, which tells us that being female will decrease the probability of liking jazz by 10 percent. On the other hand, the results presented by the logistic models (m1) are more elusive as they are presented as logged odds and are not intuitive to understand.

The linear probability model can be as accurate as the logistic model in predicting results when the probability of the binary dependent variable is not close to 0 or 1. However, if the true probability approximates 0 or 1, the predicted results by the linear probability model could be more biased, even generating the results of probabilities lie outside 0 and 1.

3.If you could only present one figure or one table with a single model and single format to show the test of the hypotheses, what would you present? Explain why.

```{r}
Table1
```

The table I would like to present to test the interaction effect of age and sex in Table 2, as it uses the second difference to tell us exactly where, across the age range, there are significant gender differences in age effects. As seen in Table 1, the gender gap in the probability of liking jazz is only significant when we compare the youngest (18-32) and oldest (60+) cohort; it shows that only for this cohort the negative effect of age on liking jazz is significantly lower for women by the difference of 0.155\* in the average marginal effect of age.

4\. Finally, on a different note, if your model for question 1) did not include income, test whether adding income to the model improves the model fit; if you already included income, test whether removing it gives a worse fit. Explain what model fit means in this context and how you make the comparison between models.

```{r}
#m1<-glm(jazz_n~ageq+sex+ageq*sex,data=gss_jazz,family = binomial(link="logit"))

#log the income to make it normally distributed
gss_jazz$income<-log(gss_jazz$income)
m3<-glm(jazz_n~ageq+sex+ageq*sex+income,data=gss_jazz,family = binomial(link="logit"))

#make the comparison between the full and nested models using the AIC, and BIC
AIC(m1,m3)
BIC(m1,m3)

table4<-modelsummary(list("Model 3"=m3),fmt=2,statistic = "conf.int",conf_level = 0.95,exponentiate = T,stars = T,title="Model 3 presented in odds ratios")
table4|>
    kable_classic(full_width = F, html_font = "Cambria")
```

Using BIC to test the goodness-of-fit of model 3 (Table 4) after adding the logged income variable compared with model 1, it's shown that there is a relatively weak increase in model fit (BICm = 2157.457, BIC\*= 2156.052, Δ BIC\<2). 

However, when using the more lenient AIC method, which imposes less penalty on adding new variables, the evidence supporting model 3 is moderately strong (AICm = 2114.699, AIC\*=2107.949, Δ AIC=6.75) (Fabozz et al.i, 2014)

In short, we conclude there is moderate evidence supporting adding the logged income variable to model 1 increases the model fit.

```{r}
rm(d1,d2,d3,d4,d5,d6,dat,design,m1_new,f1,f2,f3,f4,design_new,lpdm,lpdmp,pdm,jazz,p1,dat)
```

## SECTION A2

Some people are more worried about climate change than others. There seems to be **an association between educational attainment and level of worrying about climate change**. In climatesurvey.cvs you find data from a 2020 UK survey (part of ESS) that allows you to assess **to what extent there is an educational gradient in worrying about climate change**. Furthermore, it contains data to assess **to what extent educational differences are mediated by trust in science, generalized trust, political left/right position, religiosity, and internet use**. There are also some **socio-demographic variables**

1.  Is there an **educational difference in worrying about climate change**? To answer this question estimate a **logistic regression model that also takes into account age and gender**. Present and discuss the results.

```{r}
#look at the distribution of the variables
summary(climatesurvey)
table(is.na(climatesurvey))

#build a logistic regression model 
m4<-glm(worried~degree+age+female,data=climatesurvey,family = binomial(link="logit"))

table5<-modelsummary(list("Model 4"=m4),fmt=2,statistic = "conf.int",conf_level = 0.95,exponentiate = T,stars = T,title="Model 4 Presented in Odds ratios")
```

Table 5 summarizes the model built in odds ratios. As seen in the table we know that having a degree will increase the odd worrying about climate (2.22\*\*\*). Additionally, being female also predicts higher odds of concerning about climate change (1.42\*). Age shows no significant effect regrading the relevant concerns.

2.  Estimate a second model with mediators and compare it to the model without mediators. Think carefully about your choice of model. Explain the rationale for your approach. Present and discuss the results. What do you conclude about the contribution of the mediators?

```{r}
#assess to what extent educational differences are mediated by trust in science, generalized trust, political left/right position, religiosity, and internet use. There are also some socio-demographic variables

m5<-glm(worried~degree+age+female+trstsci+lrscale,data=climatesurvey,family = binomial(link="logit"))

```

The second model only includes variables for trusting scientists and left-right scale as mediators after model selection. The model selection rationale is backward elimination, which begins by adding all mediators possible to the model and exclude one variable which has the largest p-value at a time. The final model will only include mediators that have significant contributions to the results when controlling other variables.

In examine the contribution of the mediators, we use the khb method as even the new mediators added do not explain the effect of the variables already in the model (degree, age, and female) , the coefficient of those variables will change as the total variance of logistic regression is fixed.

```{r}
#using the khb method to compare coeffient between the full and adjusted models
khb<-khb(m4,m5)
print(khb,type="models")
print(khb,disentangle=T)

##adding trstsci
m5_trstsci<-glm(worried~degree+age+female+trstsci,data=climatesurvey,family = binomial(link="logit"))
khb1<-khb(m4,m5_trstsci)
print(khb1,type="models")
print(khb1,disentangle=T)

##adding lrscale
m5_lrscale<-glm(worried~degree+age+female+lrscale,data=climatesurvey,family = binomial(link="logit"))
khb2<-khb(m4,m5_lrscale)
print(khb2,type="models")
print(khb2,disentangle=T)

#create a table to demonstrate the khb analysis results
convertModel <- function(model) {
  tr <- createTexreg(
    coef.names = names(model$coef), 
    coef = as.numeric(summary(model)$coefficients[,1]), 
    se = as.numeric(summary(model)$coefficients[,2]), 
    pvalues = as.numeric(summary(model)$coefficients[,4]),
    gof.names = c("N","AIC"), 
    gof = c(nobs(model),AIC(model)), 
    gof.decimal = c(F,F)

  )
}
table6<-htmlreg(lapply(list(khb$reduced,khb$adjusted,khb$full), convertModel),file="khb.html",custom.model.names = c("Reduced", "Adjusted","Full"),caption="KHB test for adding mediators", 
        caption.above = TRUE)

dat1<-as.data.frame(khb$key$degree$detail)
dat2<-as.data.frame(khb$key$age$detail)
dat3<-as.data.frame(khb$key$female$detail)
dat<-rbind(dat1,dat2,dat3)
is.num <- sapply(dat, is.numeric)
dat[is.num] <- lapply(dat[is.num], round, 2)

table7<-kbl(dat,caption = "Test the change in Beta: Decomposition of the difference ")%>%
kable_classic(full_width = F, html_font = "Cambria")%>%
pack_rows("degree ",1,3)%>%
pack_rows("age ",4,6)%>%
        pack_rows("female ",7,9)
```

As seen in the khb analysis results, adding the variables related to trusting scientists or being on the political left-right spectrum makes the effects of education and age being stronger (still age do not significantly contribute to the results), besides, lrscale also partly contributes to the increase in coefficient magnitude of sex.

This may be explained as there are some suppressor effects exist in the model, and because people who are highly-educated, being younger or being female are more likely to self-select into the political left-right spectrum or have the same attitudes towards scientists, the effects of these variables are compromised if we don't add the relevant mediators.

3.  Present the results of your model from question 2) (ie the one with mediators) as marginal effects. Choose between average marginal effects and marginal effects at the mean. Explain what the difference is between these two types of marginal effects and motivate your choice. Discuss the results.

    ```{r}
    AME<-avg_slopes(m5, by = TRUE)
    summary(AME)

    ame<-AME%>%dplyr::select(term,contrast,estimate,std.error,p.value)
    is.num <- sapply(ame, is.numeric)
    ame[is.num] <- lapply(ame[is.num], round, 2)

    table7<-kbl(ame, align = "c") %>%
      kable_classic(full_width = F, html_font = "Cambria") 
    ```

Average marginal effects (AMEs) set all covariates at their original values, whilst marginal effects at the mean set all covariates at their means. In this case we prefer using the average marginal effects as it is easier for interpretation: it can be interpreted as the effect of changing one unit of x on average across all observations.

As seen in Table 7 for the summarizing AMEs, education (measured by having a degree or not) has an average marginal effect of 0.13 on the probability of worrying about climate change. Similarly, a unit increase on the political right scale has an average marginal effect of -0.04, and an unit increase in the scale for trusting scientists has an average marginal effect of 0.04 on the probability of having concerns about climate.

```{r}
rm(ame,AME,dat1,dat2,dat3,khb,khb1,khb2,m5_trstsci,m5_lrscale,is.num)

```

# Section B – Multilevel and panel models

## SECTION B1

There is a long-standing debate in social sciences about the effect of **family background and school type on pupils academic outcomes**. For B1, use the information on pupils’ **math tests, family background, and school type** in schoolsdata.csv to shed some light on this debate.

1\) What is the total variance of the math test results? Explain what this variance means.

```{r}
#explore the data
summary(schoolsdata)
table(is.na(schoolsdata))

#scale the ses variable by its grand mean
schoolsdata$ses<-schoolsdata$ses-mean(schoolsdata$ses,na.rm=T)
#make schoolid a factor


#check the number of unique student id in data 48
n_distinct(schoolsdata$pupilid)

#check the number of schools 149
n_distinct(schoolsdata$schoolid)
```

```{r}
#check what kind of variation of maths score we have across schools
schoolsdata%>%dplyr::group_by(schoolid)%>%dplyr::summarise(mean=mean(mathtest,na.rm=T),
                  SD=sd(mathtest,na.rm=T))%>%print(n=50)
```

There seems to be substantial variation in math scores between schools, which suggests that we could use a multi-level model.

```{r}
#build an empty model
m6<-lmer(mathtest~1+(1|schoolid),data=schoolsdata)
summary(m6)
```

The total variance is the sum of the within-group variance and between-group variance. In this case, it's the sum of the variance of math test results within each school and between schools (39.63+8.58=48.21).

2\) Calculate the ICC for an “empty” or “null model”. Explain what the ICC is, how you calculate it, and discuss its interpretation.

```{r}
#calculate the ICC
vcov<-as.data.frame(VarCorr(m6))
vcov[1,4]/(vcov[1,4]+vcov[2,4])
```

The ICC (intraclass correlation) calculated from the empty model is 0.178. We can say that 17.8% of the variation in math scores happens at the level of schools in which the student studies, and 82.2% of the math score variation is on account of students themselves.

ICC can be interpreted as the percentage of total variance that is found at the group level, or the correlation between the two randomly selected students' math scores in a randomly selected school.

3\) Run a random intercepts model and plot the distribution of the varying intercepts. **Discuss the plot**.

```{r}
#build a random intercepts model
m7<-lmer(mathtest~1+ses+(1|schoolid),data=schoolsdata)
summary(m7)

#ICC
vcov<-as.data.frame(VarCorr(m7))
vcov[1,4]/(vcov[1,4]+vcov[2,4])

#plot the distribution of the varying intercepts
schoolsdata$pred1<-predict(m7)

schoolsdata$schoolid<-factor(schoolsdata$schoolid)

#plot varying intercepts
figure3<-ggplot(data=schoolsdata[1:1000,],
       aes(ses,pred1,color=schoolid,group=schoolid))+
        geom_smooth(se=F,method = lm)+
        theme_bw()+
        labs(x="Parental SES",y="Mathematical Scores",color="School")

#using qqmath command to divide the schools into quartiles, each dot represents a school, with its own CI
figure4<-qqmath(ranef(m7,condVar=T))

table8<-tab_model(list(m6,m7),show.se=T,show.r2=F,dv.labels = c("Model 6(mathtest)", "Model 7(mathtest)"))
```

The results of model 7 show that as ses increases by 1, the expected math score increases by 1.69 points.

The random effects in model 7 (4.32, 37.4) are slightly smaller than those in model 6 (8.58, 39.63), suggesting that parental sessions explain some variation of math test results at both the student and school levels. The ICC for model 7 (0.104) dropped compared with model 6 (0.178), suggesting that the percentage of math scores' variations explained at the school level declines when we consider parental sessions.

Concerning the plots, Figure 3 intuitively shows that the intercepts for model 7 vary at the school level. Figure 4, which divides schools into quartiles and presents their means and confidence intervals, shows lots of points not touching 0, indicating that the school level contributes much to the math test results.

4)  Compare the simple mean of the variable mathtest in the data to the intercept (γ00) of your empty model with varying intercepts. Explain the difference/similarity.

```{r}
mean(schoolsdata$mathtest)
summary(m6)
```

The grand mean of the variable mathtest in the data is 16.38, while the intercept (γ00) for the empty model is 16.33. The grand mean is the school means of math scores weighted by their sizes, but it ignores the ICC, namely the dependence at the school level.

If we set ICC=1, the mean figure will be even smaller, and γ00 in a random intercept model always lies between the simple mean and mean if ICC=1, as the random intercept model weights school means by its variances.

To conclude, γ00 in a random intercept model considers both the school sizes and the variation at the school level, as it assumes the sample is randomly drawn from the population of schools' means. In contrast, the grand mean only considers the school sizes.

5)  Is there any evidence that **religious schools have better test results because they attract pupils with more privileged socio-economic and socio-demographic backgrounds**? Address this question with any variables and models you like. Explain your approach and choices. If you manipulate any of the variables, be sure to explain what you have done and why you have done so.

```{r}
#select the appropriate variables for analysis
#add a group-level variable: religiousschool (between-group)
m8<-lmer(mathtest~1+ses+religiousschool+(1|schoolid),data=schoolsdata)
summary(m8)
lrtest(m7,m8)

#add ethnicminority
m9<-lmer(mathtest~1+ses+religiousschool+ethnicminority+(1|schoolid),data=schoolsdata)
summary(m8)
lrtest(m8,m9)

#add singleparent
m10<-lmer(mathtest~1+ses+religiousschool+ethnicminority+singleparent+(1|schoolid),data=schoolsdata)
summary(m10)
lrtest(m9,m10)

#add female
m11<-lmer(mathtest~1+ses+religiousschool+ethnicminority+singleparent+female+(1|schoolid),data=schoolsdata)
summary(m11)
lrtest(m10,m11)

#add a group-level variable: avgses (between-group)
m12<-lmer(mathtest~1+ses+religiousschool+ethnicminority+singleparent+female+avgses+(1|schoolid),data=schoolsdata)
summary(m12)
lrtest(m11,m12)

#add a group-level variable:ses_centered (within-group) no significant improvements in model fit
m13<-lmer(mathtest~1+ses+religiousschool+ethnicminority+singleparent+female+avgses+ses_centered+(1|schoolid),data=schoolsdata)
summary(m13)
lrtest(m12,m13)

#add varying slopes: ses no significant improvements in model fit
m14<-lmer(mathtest~1+ses+religiousschool+ethnicminority+singleparent+female+avgses+(1+ses|schoolid),data=schoolsdata)
summary(m12)
lrtest(m12,m14)

#add varying slopes: religiousschool no significant improvements in model fit
m15<-lmer(mathtest~1+ses+religiousschool+ethnicminority+singleparent+female+avgses+(1+religiousschool|schoolid),data=schoolsdata)
summary(m12)
lrtest(m12,m15)

#compare only adding ses_centered and only adding avgses
m16<-lmer(mathtest~1+ses+religiousschool+ethnicminority+singleparent+female+ses_centered+(1|schoolid),data=schoolsdata)
summary(m16)
lrtest(m12,m16)

rm(m8,m9,m10,m11,m12,m13,m14,m15,m16)

```

```{r}
#build model 8 as a baseline model for comparison (without any ses variables)
m8<-lmer(mathtest~1+religiousschool+ethnicminority+singleparent+female+(1|schoolid),data=schoolsdata)
summary(m8)

#percentage of schools that are religious: 45.86% 
schoolsdata%>%dplyr::count(religiousschool)%>%
        dplyr::mutate(prop=n/sum(n))

#mean of math scores in religious schools: 17.8
mean(schoolsdata[schoolsdata$religiousschool==1,"mathtest"],na.rm=T)

#mean of math scores in not religious schools: 15.18
mean(schoolsdata[schoolsdata$religiousschool==0,"mathtest"],na.rm=T)

#difference: 2.62
mean(schoolsdata[schoolsdata$religiousschool==1,"mathtest"],na.rm=T)-mean(schoolsdata[schoolsdata$religiousschool==0,"mathtest"],na.rm=T)
```

After model selection using the likelihood ratio test by comparing each alternative model after adding a new variable or random slope, the final model for analysis is presented as model 8. We deliberately excluded all variables related to students' SES in model 8 as we wanted to analyze the mediation effect.

Some exploration of the data concerning religious schools shows that there are 45.86% of schools in the sample which are religious, and the students in religious schools achieve in average a higher math score by 2.62 compared with those in non-religious schools.

To study whether religious schools attract pupils with more privileged socio-economic and socio-demographic backgrounds, we add all variables related to students' SES in model 9 to estimate the mediation effect of SES on school types.

```{r}
#build model 9 with all variables related to ses
m9<-lmer(mathtest~1+ses+religiousschool+ethnicminority+singleparent+female+ses_centered+(1|schoolid),data=schoolsdata)
summary(m9)
lrtest(m8,m9)

table9<-tab_model(list(m8,m9),show.se=T,show.r2=F,dv.labels = c("Model 8(mathtest)", "Model 9(mathtest)"))
```

The results of Model 8 and Model 9 show that after adding variables related to students' SES to the model, the coefficient for the variable religiousschool drops sharply (from 2.62 to 1.37). A simple Z-test to test the difference between these two coefficients has a p-value \< 0.01. A likelihood ratio test conducted to compare Model 8 and Model 9 shows that Model 9 fits significantly better than Model 8 (p\<0.001).

To conclude, the data lend some evidence that students' SES tends to mediate the effect of religious schools on higher math scores. This suggests that religious schools tend to attract students from higher-SES backgrounds and thus achieve higher students' math scores on average.

However, because group size is given unequal weighting in the multi-level models, this mediation test should be interpreted cautiously.

6)  Another idea in the literature is that religious schools might benefit from a higher level of social capital and that social capital helps to weaken the link between socioeconomic background and academic performance. Test this hypothesis. Explain your approach and the steps you have taken to test the hypothesis.

To study the impact of SES is different in religious and non-religious schools, we construct a interaction term of whether the school is religious and the students' ses centered within the school (religiousXses), and adding it to model 9 (model 10).

```{r}
#construct the interaction term religiousXses
schoolsdata$religiousXses<-schoolsdata$religiousschool*schoolsdata$ses_centered

m10<-lmer(mathtest~1+ses+religiousschool+ethnicminority+singleparent+female+ses_centered+religiousXses+(1|schoolid),data=schoolsdata)

summary(m10)
lrtest(m9,m10)

table10<-tab_model(list(m10),show.se=T,show.r2=F,dv.labels = c("Model 10(mathtest)"))
```

The regression results of model 10 (Table 10) show that the average effect of a unit increase in students' SES on math scores is 1.36-0.48=0.88 in the religious schools compared with non-religious ones (1.36), and the coefficient for the interaction term religious uses is significant at the 0.01 level.

This suggests students' math scores are less influenced by their SES compared with their classmates in religious schools, which corresponds to the hypothesis. A likelihood ratio test for model 9 and model 10 provides evidence that model 10 is superior to model 9 without the interaction term (p-value=0.01).

In sum, the analysis results provide relatively solid evidence for the hypothesis that students' math scores in religious schools are less affected by their relative SES compared with their classmates, which is probably due to religious schools' higher level of social capital.

```{r}
rm(vcov)
```

## SECTION B2

For this question please use selected cases from the US National Longitudinal Survey of Youth - 1997 cohort study. This longitudinal study **follows the lives of a sample of Americans born between 1980 and 1984**. Our **subsample contains waves since the respondents were 18**. The **last wave included is from 2011**. A small selection of variables is included in nlsy18plus_selection.csv. Answer the following questions:

1.  Use the **plm package** to estimate a **“between” panel model regressing household income on being married** (no other variables in the model). **Interpret the outcome** of this regression.

```{r}
#exploring the data
table(is.na(nlsy18))
summary(nlsy18)

#how many individuals and years in the data: 4964, 14
n_distinct(nlsy18$caseid)

n_distinct(nlsy18$year)

#view the distribution of the variable year
hist(nlsy18$year)

#check if it's a balanced panel (not balanced)
is.pbalanced(nlsy18)
```

The data has cases of 4964 persons nested in 14 years and is not balanced, which means the times of individuals being observed vary from case to case.

```{r}
#cleaning the data and selecting only the relevant variables
nlsy1<-nlsy18%>%dplyr::select(caseid,year,ghhinc10_,married)

table(is.na(nlsy1))

#make income easier to interpret by dividing it by 1000
nlsy1$ghhinc10_<-nlsy1$ghhinc10_/1000

```

```{r}
#using the plm package to build the "between" panel model
m11<-plm(ghhinc10_~married,
         index="caseid",
         data=nlsy1,
         model="between")
summary(m11)


table11<-modelsummary::msummary(list("Model 11 (between)" = m11), 
stars = TRUE, statistic = c("p.value", 
        "conf.int", "std.error"))
```

The analysis results of the between panel model (model 11) demonstrate that when comparing between individuals, when one is married then his or her income will be 4.78 units higher (one unit = 1000) than other individuals on average.

2.  Still **using plm**, estimate the **“within” panel model** again **regressing household income on being married**. Present and interpret the results.

```{r}
#using the plm package to build the "within" panel model
m12<-plm(ghhinc10_~married,
         index="caseid",
         data=nlsy1,
         model="within")
summary(m12)

#using the heteroskedasticity-robust standard errors
m12$vcov <- plm::vcovHC(m12, type = "HC1")

table12<-modelsummary::msummary(list("Model 12 (within)" = m12), 
stars = TRUE, statistic = c("p.value", 
        "conf.int", "std.error"))
```

The analysis results of the within panel model (model 12) demonstrate that when the same individual becomes married then that individual's income is 7.7 units (1 unit = 1000) higher compared to their average income earn across the survey periods observed when they are not married.

3\. Explain **what the difference is between the models used in 1) and 2)**. **Compare the results of 1) and 2)** and **explain differences** if you observe any.

```{r}
summary(m11)
summary(m12)
4.78-7.7
2.92/sqrt(0.86**2+2.08**2)
```

The difference between the within and between panel model is that the "within" panel model studies the changes within individuals and efficiently controls for all time-constant variables.

In contrast, the "between" panel model studies the differences between individuals. It compares each individual against one another and ignores the individual-level changes over time.

The differences between the regressed results of model 11 and model 12 tell us that the association between being married and higher income may be stronger (7.7-4.78=2.92) when we study the changes of the same individuals instead of comparing across individuals. Nonetheless, we conducted a simple Z-test of the differences between the two coefficients, and the result was insignificant (p-value\>0.01). Thus, we cannot surely conclude there exists a difference.

4\. **How many respondents** are there in the sample? How do **different respondents contribute to the estimates you find in 2)**? Do they **all contribute something**?

```{r}
#how many individuals are in the data: 4964
n_distinct(nlsy1$caseid)

#count the number of respondents who contribute to model 12
dat<-dat<-as.data.frame(nlsy1%>%dplyr::group_by(caseid,married)%>%dplyr::count(married))

dat2<-dat%>%dplyr::group_by(caseid)%>%dplyr::summarise(change=length(married))
prop.table(table(dat2$change))

#select only those id who have changed in marital status
dat3<-dat2[which(dat2$change==2),]
changedid<-as.vector(dat3$caseid)
changedid<-nlsy1[nlsy1$caseid%in%changedid,]
#change in mean income when getting married for different individuals
changedid<-as.data.frame(changedid%>%dplyr::group_by(caseid,married)%>%dplyr::summarise(meanincome=mean(ghhinc10_)))
is.num <- sapply(changedid, is.numeric)
changedid[is.num] <- lapply(changedid[is.num], round, 2)

table13<-kbl(changedid[1:10,], align = "c") %>%kable_classic(full_width = F, html_font = "Cambria")
```

The number of respondents in the data is 4964, and the proportion of respondents who contribute to the estimates in model 12 is 43.4% (who have changed at least one time in marital status). Even though most individuals have higher incomes when they get married, there are some cases that have observations contrary to this phenomenon. For instance, Table 13 shows that when getting married, the individual with caseid 25 has a lower average income compared with the time when he/she is not married (56.51-37.02=19.49). Moreover, we should note that changing from unmarried to married may have different indications on the income compared with changing from married to divorced for the same individual. Besides, the regressed result of model 2 is also heavily influenced by the cases with more variations in the data.

5.  Test the hypothesis that the **association between becoming a parent and psychological distress is not the same for men and women**. You can add other variables to the model as you please. **You can use any package but plm is recommended.** Explain your **choices** and **how you have come to your conclusion** about the hypothesis.

```{r}
#explore the dependent variables
summary(is.na(nlsy18))
#the variables highestgrade, poorhealth, and smoke have NAs (362, 6, 40)

#make income easier to interpret by dividing it by 1000
nlsy18$ghhinc10_<-nlsy18$ghhinc10_/1000

#first build the baseline model
m13<-plm(distress~parent+age+married+cocaine+arrest+crimd+injail+ghhinc10_+highestgrade+lwparents+poorhealth+smoke+urban,
         index="caseid",
         data=nlsy18,
         model="within")
summary(m13)

#model selection
#exclude ghhinc10_
m13<-plm(distress~parent+age+married+cocaine+arrest+crimd+injail+highestgrade+lwparents+poorhealth+smoke+urban,
         index="caseid",
         data=nlsy18,
         model="within")
summary(m13)

#exclude marriage
m13<-plm(distress~parent+age+married+cocaine+arrest+crimd+injail+lwparents+poorhealth+smoke+urban,
         index="caseid",
         data=nlsy18,
         model="within")
summary(m13)

#exclude married (final model)
m13<-plm(distress~parent+age+cocaine+arrest+crimd+injail+lwparents+poorhealth+smoke+urban,
         index="caseid",
         data=nlsy18,
         model="within")
summary(m13)
```

```{r}
#create two dummies for men and women
nlsy18$men<-ifelse(nlsy18$male==1,1,0)
nlsy18$women<-ifelse(nlsy18$male==0,1,0)
```

```{r}
#test the interactions
#for women
m13a<-plm(distress~parent+age+cocaine+arrest+crimd+injail+lwparents+poorhealth+smoke+urban,
         index="caseid",
         data=nlsy18%>%filter(women==1),
         model="within")
summary(m13a)

#for men
m13b<-plm(distress~parent+age+cocaine+arrest+crimd+injail+lwparents+poorhealth+smoke+urban,
         index="caseid",
         data=nlsy18%>%filter(men==1),
         model="within") 
summary(m13b)

#using the heteroskedasticity-robust standard errors
m13$vcov <- plm::vcovHC(m13, type = "HC1")
m13a$vcov <- plm::vcovHC(m13a, type = "HC1")
m13b$vcov <- plm::vcovHC(m13b, type = "HC1")

table14<-modelsummary::msummary(list("Model 13" = m13, "Model 13a (women)" = m13a,"Model 13b (men)"=m13b), 
stars = TRUE, statistic = c("p.value", 
        "std.error"))
```

```{r}
#excluding all control variables for analysis
#for women
m13c<-plm(distress~parent,
         index="caseid",
         data=nlsy18%>%filter(women==1),
         model="within")
summary(m13c)

#for men
m13d<-plm(distress~parent,
         index="caseid",
         data=nlsy18%>%filter(men==1),
         model="within") 
summary(m13d)

#using the heteroskedasticity-robust standard errors
m13c$vcov <- plm::vcovHC(m13c, type = "HC1")
m13d$vcov <- plm::vcovHC(m13d, type = "HC1")


table15<-modelsummary::msummary(list("Model 13c (women)" = m13c, "Model 13d (men)" = m13d), 
stars = TRUE, statistic = c("p.value", 
        "std.error"))
```

To test this hypothesis, we will use the plm package with the heteroskedasticity-robust standard errors adjusting for clusters as plm is as it is one of the most used packages, and the se chosen can efficiently deal with autocorrelation and heteroskedasticity in the data.

The model selection procedure is backward elimination. We first include all possible independent variables in the model and drop the most insignificant variable to check the model fit results step-by-step. The final model (model 13) has variables that significantly contribute to the prediction of the dependent variable. To test the interaction effects of gender and becoming a parent on psychological distress, we analyze males and females separately (model 13a, model 13b). The results suggest that the effect of parenthood can reduce the probability of distress for females (-0.014) but increase the probability for males (0.045). However, the coefficients for both genders are not significant.

Accounting for males and females may self-select into some control variables we include; for instance, males are more likely to be arrested or committed a crime since last year; we also analyze model 12 by gender separately, excluding all control variables (model 13c, model 13d). The results show that women are more likely to feel less distressed because of parenthood (-0.429) than males (-0.205). A simple z-test shows that the difference between men and women, when we do not control for other variables, has a p-value smaller than 0.01.

To conclude, when we only consider whether the effect of parenthood on reducing depression depends on whether the individual being observed is male or female, then the effect is stronger in females. However, when we control for other factors (crime, cocaine use, etc.), the gender difference diminishes, probably because males and females are more likely to self-select into some cohorts.

```{r}
rm(nlsy18,nlsy1,vcov,is.num,changedid,dat,dat2,dat3)
```

# Section C – Quasi-experimental designsdesigns

## PART C2

We are interested in the **effect on hourly wages of doing a company internship as part of a vocational college degree program**. We have information on more than **700 former pupils** from **three cohorts of a vocational college**. Comparing the wages of those who did and did not do an internship might give us biased results because **other factors may influence both doing an internship and getting higher wages. Motivation and social skills, for example, could be (unobserved) factors that could increase wages and make an internship more likely**. Because of the high demand for internships and a shortage of company placements, **pupils had to achieve a gpa of at least 70 in the first years to enter the intership programme in year 3. This rule might enable to use a regression discontinuity design to estimate the effect of doing an internship**. Using the above information and the data, answer the following questions:

What kind of RDD can we run in this case, **Sharp or Fuzzy?** Explain the **difference between the two** and show **what information you used to decide between them in this case**.

```{r}
#explore the data
summary(intern)
table(is.na(intern))

```

```{r}
#check fuzzy or sharp 
dat<-as.data.frame(intern%>%
        dplyr::group_by(intern,gpa>=70)%>%
        dplyr::summarise(count=n()))

table15<-kbl(dat)%>%
kable_classic(full_width = F, html_font = "Cambria")
```

The kind of RDD we run in this case is the Sharp design, as the treatment of participation in the internship is only assigned to those students who have achieved 70 or higher in their GPA, and there is no one who has GPA lower than that value have experience internships in the data (no non-compliers).

The difference between the sharp and fuzzy design is that in sharp design no one receives the treatment below the threshold value (in this case gpa \<70), and for those above the threshold value everyone receives the treatment (in this case gpa \>=70).

In contrast, in the fuzzy design people are only more likely to receive the treatment after the threshold values, those who are below the threshold can sometimes also receive the treatment, though more unlikely. In other words, the threshold value is not a strong predictor of treatment compared with the thresholds in sharp design.

Is there **evidence of manipulation?** Explain **how you have investigated this**.\

```{r}
#is there manipulation:using the McCrary test for testing manipulation
gpa_density <- rddensity(intern$gpa, c = 70)
summary(gpa_density)

#plot the density test
figure6<-plot_density_test <- rdplotdensity(rdd = gpa_density,
                                   X = intern$gpa,
                                   type = "both")
```

We use the McCrary test in the rddensity package to test for manipulation. As seen in the plotted density test (Figure 6), the confidence intervals of those who just fall below the threshold (GPA \<70) and those above the threshold (GPA\>70) do overlap. Thus, we conclude that it is hardly possible for students to deliberately manipulate and go in or out of the internship program in the data.

**Run an RDD model**. Explain your **approach** and present the **results**. To what extent does your conclusion depend on your choices about the **model** and the **bandwidth**? Explain your choices and discuss your conclusions

```{r}
#is there discontinuity in the outcome
figure7<-ggplot(intern,aes(x=gpa,y=hrwage,color=as.factor(intern)))+geom_point(size=0,alpha=0)+geom_smooth(data=filter(intern,gpa>=70),method = "lm")+geom_smooth(data=filter(intern,gpa<70),method = "lm")+geom_vline(xintercept=70)+labs(x="GPA",y="Hourly Wages",color="Intern")
```

```{r}
#check if all covariates are continuous at the treatment x
#namely no jumps at gpa >=70 at any other variables, only for intern and hrwage

#cohort
dat<-as.data.frame(intern%>%
        dplyr::group_by(cohort,gpa>=70)%>%
        dplyr::summarise(count=n()))
prop.table(dat$count)


#male:a relatively big jump at the threshold for students' sex
#there are considerably more females after the threshold, but there are still some overlaps in the confidence interval
figure8<-ggplot(intern,aes(x=gpa,y=male))+geom_point(size=0,alpha=0)+geom_smooth(data=filter(intern,gpa>=70),method = "glm", method.args = list(family = "binomial"))+geom_smooth(data=filter(intern,gpa<70),method = "glm", method.args = list(family = "binomial"))+geom_vline(xintercept=70)+labs(x="GPA",y="Student's Sex")



#sei: a little jump at the threshold 
ggplot(intern,aes(x=gpa,y=sei))+geom_point(size=0,alpha=0)+geom_smooth(data=filter(intern,gpa>=70),method = "lm")+geom_smooth(data=filter(intern,gpa<70),method = "lm")+geom_vline(xintercept=70)+labs(x="GPA",y="Student's SES at time of admission")
```

For the model assumptions testing, Figure 7 shows there is a significant discontinuity in the outcome. It should be noted that the treatment variable (intern) and the threshold (GPA \>=70) are aligned in the sharp design in this case.

We have also checked if all covariates defined are continuous at treatment x; the results show that the biggest jump in the covariate is students' sex. Figure 8 indicates that there are more male students after the threshold (GPA=70). However, there are still some overlaps in the confidence interval of students' sex around the threshold, so we continue the RDD analysis.

```{r}
#how big is the gap
#first center the gpa around the cutoff
intern<-intern%>%dplyr::mutate(gpa_centered=gpa-70)

m14<-lm(hrwage~gpa_centered+intern+factor(cohort)+male+sei,data=intern)
summary(m14)
```

```{r}
#using different bandwidths
#bandwidth=10
m14a<-lm(hrwage~gpa_centered+intern+factor(cohort)+male+sei,data=dplyr::filter(intern,gpa_centered>=-10 & gpa_centered<=10))
summary(m14a)

#bandwidth=5
m14b<-lm(hrwage~gpa_centered+intern+factor(cohort)+male+sei,data=dplyr::filter(intern,gpa_centered>=-5 & gpa_centered<=5))
summary(m14b)

```

```{r}
#how big is the gap (non-parametric)
m15<-rdrobust(y=intern$hrwage,x=intern$gpa,covs = intern$male+intern$sei+intern$cohort,c=70)


```

```{r}
#make a model list summary
table16<-modelsummary(list("Full data (Model 14)"=m14, "Bandwidth=10 (Model 14a)"=m14a,"Bandwidth=5 (Model 14b)"=m14b),stars = T)

```

To check how big is the gap around the threshold, we first use the parametric method to analyze the causal effect of participating in the internship (gpa \>=70) for the students' hourly wages two years after college, with relevant control variables.

For easier interpretation, we first code a new variable, gpa_centered, to centre the students' GPA around the threshold.

The regressed results of the full model (model 14 in Table 16) shows that when using the gpa as an instrument, we see students who have participated in the internship receive an hour wage 3.16 constant Euros higher compared with other students two years after graduation. 

When choosing different bandwidths to better mimic an experiment, the effect of internship is 1.69\*\*\* when bandwidth equals to 10 (model 14a in Table 16), and to make the argument more convincingly, the effect of internship remains significant at the value of 2.34\*\*\* when bandwidth is equal to 5 (model 14b in Table 16).

We should know that when bandwidth is narrower, whether receiving the treatment of internship is more random for the students, as it's hard for students to manipulate their scores to fall just beyond or below the threshold to receive the treatment or not. 

Consequently, when using the narrower bandwidths, the results generated by the RDD approach will be more approximate to an experiment.

In addition, we should be careful in interpreting the effect of internship as a local average treatment effect in this case because we only study the treatment effects on students who fall within the bandwidths around the threshold (gpa=70). 

Apart from the parametric method, we also use the non-parametric approach to determine the algorithm's shape based on the data. The results show that the effect of internship remains significant (2.29\*\*\*). The kernel used is the triangular to weigh more distant data with less linearity. It should be noted that the covariate of the students' cohort is fitted as a numeric value in this case.

In conclusion, we can state that there is a relatively strong local average treatment effect of internship on students' increased hourly wage after graduation in the data. 
